{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# ============================================================\n","# STEP 1 â€” Google Drive + Imports\n","# ============================================================\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","import pickle\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","# ============================================================\n","# STEP 2 â€” Load SPEED-only Normalized Data\n","# ============================================================\n","data_dir = \"/content/drive/MyDrive/traffic_data\"\n","\n","train_full = np.load(f\"{data_dir}/train_speed_norm.npz\")[\"data\"]  # (36481, 325)\n","val_full   = np.load(f\"{data_dir}/val_speed_norm.npz\")[\"data\"]    # (5211, 325)\n","test_full  = np.load(f\"{data_dir}/test_speed_norm.npz\")[\"data\"]   # (10424, 325)\n","\n","print(\"Loaded shapes:\", train_full.shape, val_full.shape, test_full.shape)\n","\n","train_data = train_full\n","val_data   = val_full\n","test_data  = test_full\n","\n","print(\"Train shape:\", train_data.shape)\n","print(\"Val shape:\",   val_data.shape)\n","print(\"Test shape:\",  test_data.shape)\n","\n","# ============================================================\n","# STEP 3 â€” Load REAL 325Ã—325 Adjacency Matrix\n","# ============================================================\n","adj_path = f\"{data_dir}/adj_mx_bay.pkl/adj_mx_bay.pkl\"\n","\n","with open(adj_path, \"rb\") as f:\n","    sensor_ids, sensor_id_to_ind, adj_mx = pickle.load(f, encoding=\"latin1\")\n","\n","adj_mx = np.array(adj_mx).astype(np.float32)\n","NUM_NODES = adj_mx.shape[0]\n","\n","print(\"Adjacency shape:\", adj_mx.shape)   # (325, 325)\n","\n","# ============================================================\n","# STEP 4 â€” Build Temporal Sequences (speed-only)\n","# ============================================================\n","def create_sequences(data, seq_len=12, pred_len=3):\n","    \"\"\"\n","    data: (T, N)\n","    returns:\n","       X: (B, seq_len, N, 1)\n","       Y: (B, pred_len, N, 1)\n","    \"\"\"\n","    T = data.shape[0]\n","    X, Y = [], []\n","\n","    for i in range(T - seq_len - pred_len):\n","        seq_x = data[i:i+seq_len]                  # (seq_len, 325)\n","        seq_y = data[i+seq_len:i+seq_len+pred_len] # (pred_len, 325)\n","\n","        X.append(seq_x[..., None])  # Add feature dim â†’ (seq_len, 325, 1)\n","        Y.append(seq_y[..., None])\n","\n","    return np.array(X), np.array(Y)\n","\n","# Build sequences\n","seq_len = 12\n","pred_len = 3\n","\n","X_train, Y_train = create_sequences(train_data, seq_len, pred_len)\n","X_val, Y_val     = create_sequences(val_data, seq_len, pred_len)\n","X_test, Y_test   = create_sequences(test_data, seq_len, pred_len)\n","\n","print(\"X_train:\", X_train.shape)\n","print(\"Y_train:\", Y_train.shape)\n","\n","# ============================================================\n","# STEP 5 â€” DataLoaders\n","# ============================================================\n","def to_loader(X, Y, batch_size=32, shuffle=True):\n","    return DataLoader(\n","        TensorDataset(torch.FloatTensor(X), torch.FloatTensor(Y)),\n","        batch_size=batch_size,\n","        shuffle=shuffle\n","    )\n","\n","train_loader = to_loader(X_train, Y_train)\n","val_loader   = to_loader(X_val, Y_val)\n","test_loader  = to_loader(X_test, Y_test)\n","\n","# ============================================================\n","# STEP 6 â€” MULTI-LAYER DCRNN MODEL (5 layers Ã— 128 hidden)\n","# ============================================================\n","class DiffusionConv(nn.Module):\n","    def __init__(self, num_nodes, input_dim, output_dim, dropout=0.2):\n","        super().__init__()\n","        self.theta = nn.Parameter(torch.randn(input_dim, output_dim))\n","        nn.init.xavier_uniform_(self.theta)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, adj):\n","        out = torch.einsum(\"ij,bjf->bif\", adj, x)\n","        out = torch.einsum(\"bif,fo->bio\", out, self.theta)\n","        return self.dropout(out)\n","\n","\n","class DCRNNCell(nn.Module):\n","    def __init__(self, num_nodes, input_dim, hidden_dim, dropout=0.2):\n","        super().__init__()\n","        self.num_nodes = num_nodes\n","        self.hidden_dim = hidden_dim\n","\n","        self.diff = DiffusionConv(num_nodes, input_dim + hidden_dim, hidden_dim, dropout)\n","        self.gru = nn.GRUCell(hidden_dim, hidden_dim)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, h_prev, adj):\n","        combined = torch.cat([x, h_prev], dim=-1)\n","        diff_out = self.dropout(self.diff(combined, adj))\n","        h_new = self.gru(diff_out.reshape(-1, self.hidden_dim),\n","                         h_prev.reshape(-1, self.hidden_dim))\n","        return h_new.reshape(-1, self.num_nodes, self.hidden_dim)\n","\n","\n","class DCRNN(nn.Module):\n","    def __init__(self, num_nodes, input_dim, hidden_dim, output_dim, adj, num_layers=5, dropout=0.2):\n","        super().__init__()\n","\n","        self.layers = nn.ModuleList()\n","        self.layers.append(DCRNNCell(num_nodes, input_dim, hidden_dim, dropout))\n","        for _ in range(num_layers - 1):\n","            self.layers.append(DCRNNCell(num_nodes, hidden_dim, hidden_dim, dropout))\n","\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","        self.register_buffer(\"adj\", torch.FloatTensor(adj))\n","\n","    def forward(self, x):\n","        B, T, N, F = x.shape\n","        h = [torch.zeros(B, N, hidden_dim, device=x.device) for _ in range(len(self.layers))]\n","\n","        for t in range(T):\n","            input_t = x[:, t]   # (B, 325, 1)\n","            for l, layer in enumerate(self.layers):\n","                h[l] = layer(input_t, h[l], self.adj)\n","                input_t = h[l]  # Pass output to next layer\n","\n","        out = self.fc(input_t)    # (B, 325, 1)\n","        return out.unsqueeze(1)   # (B, 1, 325, 1)\n","\n","# ============================================================\n","# STEP 7 â€” TRAINING (with best model saving)\n","# ============================================================\n","input_dim = 1\n","hidden_dim = 128\n","output_dim = 1\n","\n","model = DCRNN(NUM_NODES, input_dim, hidden_dim, output_dim, adj_mx, num_layers=5, dropout=0.2).to(device)\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","criterion = nn.MSELoss()\n","\n","EPOCHS = 50\n","best_val_loss = float(\"inf\")\n","best_model_path = f\"{data_dir}/dcrnn_speed_best.pth\"\n","\n","for epoch in range(EPOCHS):\n","\n","    model.train()\n","    train_loss = 0.0\n","\n","    for Xb, Yb in train_loader:\n","        Xb, Yb = Xb.to(device), Yb.to(device)\n","\n","        optimizer.zero_grad()\n","        preds = model(Xb)                 # (B, 1, 325, 1)\n","        target = Yb[:, -1:]               # final step (B, 1, 325, 1)\n","\n","        loss = criterion(preds, target)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item()\n","\n","    # ---- Validation ----\n","    model.eval()\n","    val_loss = 0.0\n","    with torch.no_grad():\n","        for Xb, Yb in val_loader:\n","            preds = model(Xb.to(device))\n","            target = Yb[:, -1:].to(device)\n","            val_loss += criterion(preds, target).item()\n","\n","    avg_train = train_loss / len(train_loader)\n","    avg_val = val_loss / len(val_loader)\n","\n","    print(f\"Epoch {epoch+1}/{EPOCHS}  Train={avg_train:.6f}  Val={avg_val:.6f}\")\n","\n","    if avg_val < best_val_loss:\n","        best_val_loss = avg_val\n","        torch.save(model.state_dict(), best_model_path)\n","        print(f\"ðŸ”¥ Best model saved (Val={best_val_loss:.6f}) â†’ {best_model_path}\")\n","\n","print(\"\\nTraining complete!\")\n","print(f\"Best model saved at: {best_model_path}\")\n"],"metadata":{"id":"MvmhrxNM4p8n","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c3ea61a9-3c79-4731-d22e-84836ddd868f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Using device: cuda\n","Loaded shapes: (36481, 325) (5211, 325) (10424, 325)\n","Train shape: (36481, 325)\n","Val shape: (5211, 325)\n","Test shape: (10424, 325)\n","Adjacency shape: (325, 325)\n","X_train: (36466, 12, 325, 1)\n","Y_train: (36466, 3, 325, 1)\n","Epoch 1/50  Train=0.426151  Val=0.436007\n","ðŸ”¥ Best model saved (Val=0.436007) â†’ /content/drive/MyDrive/traffic_data/dcrnn_speed_best.pth\n"]}]},{"cell_type":"markdown","source":["128 - Hidden Dimension"],"metadata":{"id":"A9Dh6Rm4z2QV"}},{"cell_type":"code","source":["# ============================================================\n","# STEP 1 â€” Google Drive + Imports\n","# ============================================================\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","import pickle\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","# ============================================================\n","# STEP 2 â€” Load Normalized Data\n","# ============================================================\n","data_dir = \"/content/drive/MyDrive/traffic_data\"\n","\n","train_full = np.load(f\"{data_dir}/train_norm_PEMS_BAY.npz\")[\"data\"]\n","val_full   = np.load(f\"{data_dir}/val_norm_PEMS_BAY.npz\")[\"data\"]\n","test_full  = np.load(f\"{data_dir}/test_norm_PEMS_BAY.npz\")[\"data\"]\n","\n","print(\"Loaded shapes:\", train_full.shape, val_full.shape, test_full.shape)\n","\n","# Limit timesteps EXACTLY as requested\n","train_data = train_full[:36481]   # (1000, 325, 3)\n","val_data   = val_full[:5211]      # (100, 325, 3)\n","test_data  = test_full[:10424]     # (200, 325, 3)\n","\n","print(\"Train shape:\", train_data.shape)\n","print(\"Val shape:\",   val_data.shape)\n","print(\"Test shape:\",  test_data.shape)\n","\n","# ============================================================\n","# STEP 3 â€” Load REAL 325Ã—325 Adjacency Matrix\n","# ============================================================\n","adj_path = f\"{data_dir}/adj_mx_bay.pkl/adj_mx_bay.pkl\"\n","\n","with open(adj_path, \"rb\") as f:\n","    sensor_ids, sensor_id_to_ind, adj_mx = pickle.load(f, encoding=\"latin1\")\n","\n","adj_mx = np.array(adj_mx).astype(np.float32)\n","NUM_NODES = adj_mx.shape[0]\n","\n","print(\"Adjacency shape:\", adj_mx.shape)   # (325, 325)\n","\n","\n","# ============================================================\n","# STEP 4 â€” Build Temporal Sequences\n","# ============================================================\n","def create_sequences(data, seq_len=12, pred_len=3):\n","    \"\"\"\n","    data: (T, N, F)\n","    returns:\n","       X: (B, seq_len, N, F)\n","       Y: (B, pred_len, N, F)\n","    \"\"\"\n","    T = data.shape[0]\n","    X, Y = [], []\n","\n","    for i in range(T - seq_len - pred_len):\n","        X.append(data[i:i+seq_len])\n","        Y.append(data[i+seq_len:i+seq_len+pred_len])\n","\n","    X = np.array(X)\n","    Y = np.array(Y)\n","    return X, Y\n","\n","# Build sequences\n","seq_len = 12\n","pred_len = 3\n","\n","X_train, Y_train = create_sequences(train_data, seq_len, pred_len)\n","X_val, Y_val     = create_sequences(val_data, seq_len, pred_len)\n","X_test, Y_test   = create_sequences(test_data, seq_len, pred_len)\n","\n","print(\"Sequence shapes:\")\n","print(\"X_train:\", X_train.shape)\n","print(\"Y_train:\", Y_train.shape)\n","\n","\n","# ============================================================\n","# STEP 5 â€” DataLoaders\n","# ============================================================\n","def to_loader(X, Y, batch=32, shuffle=True):\n","    return DataLoader(\n","        TensorDataset(torch.FloatTensor(X), torch.FloatTensor(Y)),\n","        batch_size=batch,\n","        shuffle=shuffle\n","    )\n","\n","train_loader = to_loader(X_train, Y_train)\n","val_loader   = to_loader(X_val, Y_val)\n","test_loader  = to_loader(X_test, Y_test)\n","\n","\n","# ============================================================\n","# STEP 6 â€” DCRNN MODEL\n","# ============================================================\n","# ============================================================\n","# STEP 6 â€” DCRNN MODEL (with dropout=0.2)\n","# ============================================================\n","# ============================================================\n","# STEP 6 â€” Multilayer DCRNN (5 layers, 128 units each, dropout=0.2)\n","# ============================================================\n","class DiffusionConv(nn.Module):\n","    def __init__(self, num_nodes, input_dim, output_dim, dropout=0.2):\n","        super().__init__()\n","        self.theta = nn.Parameter(torch.randn(input_dim, output_dim))\n","        nn.init.xavier_uniform_(self.theta)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, adj):\n","        # x: (B, N, F)\n","        out = torch.einsum(\"ij,bjf->bif\", adj, x)        # diffusion step\n","        out = torch.einsum(\"bif,fo->bio\", out, self.theta)\n","        out = self.dropout(out)                          # dropout\n","        return out\n","\n","\n","class DCRNNCell(nn.Module):\n","    def __init__(self, num_nodes, input_dim, hidden_dim, dropout=0.2):\n","        super().__init__()\n","        self.num_nodes = num_nodes\n","        self.hidden_dim = hidden_dim\n","\n","        self.diff = DiffusionConv(num_nodes, input_dim + hidden_dim, hidden_dim, dropout)\n","        self.gru = nn.GRUCell(hidden_dim, hidden_dim)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, h_prev, adj):\n","        combined = torch.cat([x, h_prev], dim=-1)\n","        diff_out = self.diff(combined, adj)\n","        diff_out = self.dropout(diff_out)\n","        h_new = self.gru(diff_out.reshape(-1, self.hidden_dim),\n","                         h_prev.reshape(-1, self.hidden_dim))\n","        return h_new.reshape(-1, self.num_nodes, self.hidden_dim)\n","\n","\n","class DCRNN(nn.Module):\n","    def __init__(self, num_nodes, input_dim, hidden_dim, output_dim, adj, dropout=0.2, num_layers=5):\n","        super().__init__()\n","        self.num_nodes = num_nodes\n","        self.hidden_dim = hidden_dim\n","        self.num_layers = num_layers\n","\n","        # -------- Create 5 stacked DCRNN layers --------\n","        layers = []\n","        for i in range(num_layers):\n","            in_dim = input_dim if i == 0 else hidden_dim\n","            layers.append(DCRNNCell(num_nodes, in_dim, hidden_dim, dropout))\n","\n","        self.layers = nn.ModuleList(layers)\n","\n","        # Final output projection\n","        self.fc_dropout = nn.Dropout(dropout)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","        self.register_buffer(\"adj\", torch.FloatTensor(adj))\n","\n","    def forward(self, x):\n","        B, T, N, F = x.shape\n","        h = [torch.zeros(B, N, self.hidden_dim, device=x.device)\n","             for _ in range(self.num_layers)]\n","\n","        for t in range(T):\n","            input_t = x[:, t]   # (B, N, F)\n","            for l in range(self.num_layers):\n","                h[l] = self.layers[l](input_t, h[l], self.adj)\n","                input_t = h[l]   # output of one layer becomes input to next\n","\n","        out = self.fc_dropout(h[-1])\n","        out = self.fc(out)\n","        return out.unsqueeze(1)\n","\n","\n","\n","\n","# ============================================================\n","# STEP 7 â€” TRAIN DCRNN\n","# ============================================================\n","# ============================================================\n","# STEP 7 â€” TRAIN DCRNN (Save best validation model)\n","# ============================================================\n","input_dim = 3\n","hidden_dim = 128\n","output_dim = 1\n","\n","model = DCRNN(NUM_NODES, input_dim, hidden_dim, output_dim, adj_mx, dropout=0.2, num_layers=5).to(device)\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","criterion = nn.MSELoss()\n","\n","EPOCHS = 50\n","best_val_loss = float('inf')    # Track best loss\n","\n","best_model_path = f\"{data_dir}/dcrnn_325nodes_best.pth\"\n","\n","for epoch in range(EPOCHS):\n","    # ------------------------\n","    # TRAINING\n","    # ------------------------\n","    model.train()\n","    train_loss = 0\n","\n","    for Xb, Yb in train_loader:\n","        Xb, Yb = Xb.to(device), Yb.to(device)\n","        optimizer.zero_grad()\n","\n","        preds = model(Xb)               # (B, 1, N, 1)\n","        target = Yb[:, -1:, :, 0:1]     # final step target\n","\n","        loss = criterion(preds, target)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item()\n","\n","    # ------------------------\n","    # VALIDATION\n","    # ------------------------\n","    model.eval()\n","    val_loss = 0\n","    with torch.no_grad():\n","        for Xb, Yb in val_loader:\n","            preds = model(Xb.to(device))\n","            target = Yb[:, -1:, :, 0:1].to(device)\n","            val_loss += criterion(preds, target).item()\n","\n","    avg_train = train_loss / len(train_loader)\n","    avg_val   = val_loss   / len(val_loader)\n","\n","    print(f\"Epoch {epoch+1}/{EPOCHS}  Train={avg_train:.6f}  Val={avg_val:.6f}\")\n","\n","    # ------------------------\n","    # SAVE BEST MODEL\n","    # ------------------------\n","    if avg_val < best_val_loss:\n","        best_val_loss = avg_val\n","        torch.save(model.state_dict(), best_model_path)\n","        print(f\"ðŸ”¥ Saved BEST model (Val loss = {best_val_loss:.6f}) at: {best_model_path}\")\n","\n","# ============================================================\n","# FINAL PRINT\n","# ============================================================\n","print(f\"\\nTraining done. Best model saved at:\\n â†’ {best_model_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MDr8Y2qhzyBC","executionInfo":{"status":"ok","timestamp":1764023441468,"user_tz":300,"elapsed":2954952,"user":{"displayName":"Krishna Sharma","userId":"06839551360419294155"}},"outputId":"1f971ccb-7bf7-4749-d33b-c46b472b16ab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Using device: cuda\n","Loaded shapes: (36481, 325, 3) (5211, 325, 3) (10424, 325, 3)\n","Train shape: (36481, 325, 3)\n","Val shape: (5211, 325, 3)\n","Test shape: (10424, 325, 3)\n","Adjacency shape: (325, 325)\n","Sequence shapes:\n","X_train: (36466, 12, 325, 3)\n","Y_train: (36466, 3, 325, 3)\n","Epoch 1/50  Train=0.256532  Val=0.274483\n","ðŸ”¥ Saved BEST model (Val loss = 0.274483) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 2/50  Train=0.225064  Val=0.264221\n","ðŸ”¥ Saved BEST model (Val loss = 0.264221) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 3/50  Train=0.220301  Val=0.263189\n","ðŸ”¥ Saved BEST model (Val loss = 0.263189) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 4/50  Train=0.217802  Val=0.258601\n","ðŸ”¥ Saved BEST model (Val loss = 0.258601) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 5/50  Train=0.216093  Val=0.258162\n","ðŸ”¥ Saved BEST model (Val loss = 0.258162) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 6/50  Train=0.214200  Val=0.254192\n","ðŸ”¥ Saved BEST model (Val loss = 0.254192) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 7/50  Train=0.213958  Val=0.253399\n","ðŸ”¥ Saved BEST model (Val loss = 0.253399) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 8/50  Train=0.211556  Val=0.252029\n","ðŸ”¥ Saved BEST model (Val loss = 0.252029) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 9/50  Train=0.210801  Val=0.248282\n","ðŸ”¥ Saved BEST model (Val loss = 0.248282) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 10/50  Train=0.209540  Val=0.250157\n","Epoch 11/50  Train=0.209048  Val=0.248036\n","ðŸ”¥ Saved BEST model (Val loss = 0.248036) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 12/50  Train=0.208027  Val=0.248465\n","Epoch 13/50  Train=0.207493  Val=0.245926\n","ðŸ”¥ Saved BEST model (Val loss = 0.245926) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 14/50  Train=0.206813  Val=0.246890\n","Epoch 15/50  Train=0.206111  Val=0.243479\n","ðŸ”¥ Saved BEST model (Val loss = 0.243479) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 16/50  Train=0.205681  Val=0.244013\n","Epoch 17/50  Train=0.204843  Val=0.243547\n","Epoch 18/50  Train=0.204684  Val=0.242169\n","ðŸ”¥ Saved BEST model (Val loss = 0.242169) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 19/50  Train=0.204000  Val=0.242136\n","ðŸ”¥ Saved BEST model (Val loss = 0.242136) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 20/50  Train=0.203712  Val=0.244426\n","Epoch 21/50  Train=0.203257  Val=0.242790\n","Epoch 22/50  Train=0.202806  Val=0.243169\n","Epoch 23/50  Train=0.202465  Val=0.239985\n","ðŸ”¥ Saved BEST model (Val loss = 0.239985) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 24/50  Train=0.202145  Val=0.238243\n","ðŸ”¥ Saved BEST model (Val loss = 0.238243) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 25/50  Train=0.201635  Val=0.240464\n","Epoch 26/50  Train=0.201329  Val=0.238318\n","Epoch 27/50  Train=0.201153  Val=0.239550\n","Epoch 28/50  Train=0.200678  Val=0.241233\n","Epoch 29/50  Train=0.200156  Val=0.239955\n","Epoch 30/50  Train=0.200157  Val=0.237688\n","ðŸ”¥ Saved BEST model (Val loss = 0.237688) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 31/50  Train=0.199932  Val=0.237053\n","ðŸ”¥ Saved BEST model (Val loss = 0.237053) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 32/50  Train=0.199410  Val=0.236633\n","ðŸ”¥ Saved BEST model (Val loss = 0.236633) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 33/50  Train=0.199302  Val=0.238375\n","Epoch 34/50  Train=0.199132  Val=0.237254\n","Epoch 35/50  Train=0.198714  Val=0.236891\n","Epoch 36/50  Train=0.198610  Val=0.235313\n","ðŸ”¥ Saved BEST model (Val loss = 0.235313) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 37/50  Train=0.198036  Val=0.237676\n","Epoch 38/50  Train=0.197895  Val=0.235466\n","Epoch 39/50  Train=0.197569  Val=0.236563\n","Epoch 40/50  Train=0.197919  Val=0.235254\n","ðŸ”¥ Saved BEST model (Val loss = 0.235254) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 41/50  Train=0.197297  Val=0.237562\n","Epoch 42/50  Train=0.197040  Val=0.235009\n","ðŸ”¥ Saved BEST model (Val loss = 0.235009) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 43/50  Train=0.196721  Val=0.234932\n","ðŸ”¥ Saved BEST model (Val loss = 0.234932) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 44/50  Train=0.196716  Val=0.234143\n","ðŸ”¥ Saved BEST model (Val loss = 0.234143) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 45/50  Train=0.196421  Val=0.235764\n","Epoch 46/50  Train=0.196184  Val=0.234774\n","Epoch 47/50  Train=0.196018  Val=0.236032\n","Epoch 48/50  Train=0.195858  Val=0.233260\n","ðŸ”¥ Saved BEST model (Val loss = 0.233260) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 49/50  Train=0.195724  Val=0.236317\n","Epoch 50/50  Train=0.195682  Val=0.234559\n","\n","Training done. Best model saved at:\n"," â†’ /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n"]}]},{"cell_type":"markdown","source":["Multilayer DCRNN (3 layers, 64 units each, dropout=0.2)\n"],"metadata":{"id":"M6DMYKlpAUk8"}},{"cell_type":"code","source":["# ============================================================\n","# STEP 1 â€” Google Drive + Imports\n","# ============================================================\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","import pickle\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","# ============================================================\n","# STEP 2 â€” Load Normalized Data\n","# ============================================================\n","data_dir = \"/content/drive/MyDrive/traffic_data\"\n","\n","train_full = np.load(f\"{data_dir}/train_norm_PEMS_BAY.npz\")[\"data\"]\n","val_full   = np.load(f\"{data_dir}/val_norm_PEMS_BAY.npz\")[\"data\"]\n","test_full  = np.load(f\"{data_dir}/test_norm_PEMS_BAY.npz\")[\"data\"]\n","\n","print(\"Loaded shapes:\", train_full.shape, val_full.shape, test_full.shape)\n","\n","# Limit timesteps EXACTLY as requested\n","train_data = train_full[:36481]   # (1000, 325, 3)\n","val_data   = val_full[:5211]      # (100, 325, 3)\n","test_data  = test_full[:10424]     # (200, 325, 3)\n","\n","print(\"Train shape:\", train_data.shape)\n","print(\"Val shape:\",   val_data.shape)\n","print(\"Test shape:\",  test_data.shape)\n","\n","# ============================================================\n","# STEP 3 â€” Load REAL 325Ã—325 Adjacency Matrix\n","# ============================================================\n","adj_path = f\"{data_dir}/adj_mx_bay.pkl/adj_mx_bay.pkl\"\n","\n","with open(adj_path, \"rb\") as f:\n","    sensor_ids, sensor_id_to_ind, adj_mx = pickle.load(f, encoding=\"latin1\")\n","\n","adj_mx = np.array(adj_mx).astype(np.float32)\n","NUM_NODES = adj_mx.shape[0]\n","\n","print(\"Adjacency shape:\", adj_mx.shape)   # (325, 325)\n","\n","\n","# ============================================================\n","# STEP 4 â€” Build Temporal Sequences\n","# ============================================================\n","def create_sequences(data, seq_len=12, pred_len=3):\n","    \"\"\"\n","    data: (T, N, F)\n","    returns:\n","       X: (B, seq_len, N, F)\n","       Y: (B, pred_len, N, F)\n","    \"\"\"\n","    T = data.shape[0]\n","    X, Y = [], []\n","\n","    for i in range(T - seq_len - pred_len):\n","        X.append(data[i:i+seq_len])\n","        Y.append(data[i+seq_len:i+seq_len+pred_len])\n","\n","    X = np.array(X)\n","    Y = np.array(Y)\n","    return X, Y\n","\n","# Build sequences\n","seq_len = 12\n","pred_len = 3\n","\n","X_train, Y_train = create_sequences(train_data, seq_len, pred_len)\n","X_val, Y_val     = create_sequences(val_data, seq_len, pred_len)\n","X_test, Y_test   = create_sequences(test_data, seq_len, pred_len)\n","\n","print(\"Sequence shapes:\")\n","print(\"X_train:\", X_train.shape)\n","print(\"Y_train:\", Y_train.shape)\n","\n","\n","# ============================================================\n","# STEP 5 â€” DataLoaders\n","# ============================================================\n","def to_loader(X, Y, batch=32, shuffle=True):\n","    return DataLoader(\n","        TensorDataset(torch.FloatTensor(X), torch.FloatTensor(Y)),\n","        batch_size=batch,\n","        shuffle=shuffle\n","    )\n","\n","train_loader = to_loader(X_train, Y_train)\n","val_loader   = to_loader(X_val, Y_val)\n","test_loader  = to_loader(X_test, Y_test)\n","\n","\n","# ============================================================\n","# STEP 6 â€” DCRNN MODEL\n","# ============================================================\n","# ============================================================\n","# STEP 6 â€” DCRNN MODEL (with dropout=0.2)\n","# ============================================================\n","# ============================================================\n","# STEP 6 â€” Multilayer DCRNN (3 layers, 64 units each, dropout=0.2)\n","# ============================================================\n","class DiffusionConv(nn.Module):\n","    def __init__(self, num_nodes, input_dim, output_dim, dropout=0.2):\n","        super().__init__()\n","        self.theta = nn.Parameter(torch.randn(input_dim, output_dim))\n","        nn.init.xavier_uniform_(self.theta)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, adj):\n","        # x: (B, N, F)\n","        out = torch.einsum(\"ij,bjf->bif\", adj, x)        # diffusion step\n","        out = torch.einsum(\"bif,fo->bio\", out, self.theta)\n","        out = self.dropout(out)                          # dropout\n","        return out\n","\n","\n","class DCRNNCell(nn.Module):\n","    def __init__(self, num_nodes, input_dim, hidden_dim, dropout=0.2):\n","        super().__init__()\n","        self.num_nodes = num_nodes\n","        self.hidden_dim = hidden_dim\n","\n","        self.diff = DiffusionConv(num_nodes, input_dim + hidden_dim, hidden_dim, dropout)\n","        self.gru = nn.GRUCell(hidden_dim, hidden_dim)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, h_prev, adj):\n","        combined = torch.cat([x, h_prev], dim=-1)\n","        diff_out = self.diff(combined, adj)\n","        diff_out = self.dropout(diff_out)\n","        h_new = self.gru(diff_out.reshape(-1, self.hidden_dim),\n","                         h_prev.reshape(-1, self.hidden_dim))\n","        return h_new.reshape(-1, self.num_nodes, self.hidden_dim)\n","\n","\n","class DCRNN(nn.Module):\n","    def __init__(self, num_nodes, input_dim, hidden_dim, output_dim, adj, dropout=0.2, num_layers=5):\n","        super().__init__()\n","        self.num_nodes = num_nodes\n","        self.hidden_dim = hidden_dim\n","        self.num_layers = num_layers\n","\n","        # -------- Create 5 stacked DCRNN layers --------\n","        layers = []\n","        for i in range(num_layers):\n","            in_dim = input_dim if i == 0 else hidden_dim\n","            layers.append(DCRNNCell(num_nodes, in_dim, hidden_dim, dropout))\n","\n","        self.layers = nn.ModuleList(layers)\n","\n","        # Final output projection\n","        self.fc_dropout = nn.Dropout(dropout)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","        self.register_buffer(\"adj\", torch.FloatTensor(adj))\n","\n","    def forward(self, x):\n","        B, T, N, F = x.shape\n","        h = [torch.zeros(B, N, self.hidden_dim, device=x.device)\n","             for _ in range(self.num_layers)]\n","\n","        for t in range(T):\n","            input_t = x[:, t]   # (B, N, F)\n","            for l in range(self.num_layers):\n","                h[l] = self.layers[l](input_t, h[l], self.adj)\n","                input_t = h[l]   # output of one layer becomes input to next\n","\n","        out = self.fc_dropout(h[-1])\n","        out = self.fc(out)\n","        return out.unsqueeze(1)\n","\n","\n","\n","\n","# ============================================================\n","# STEP 7 â€” TRAIN DCRNN\n","# ============================================================\n","# ============================================================\n","# STEP 7 â€” TRAIN DCRNN (Save best validation model)\n","# ============================================================\n","input_dim = 3\n","hidden_dim = 64\n","output_dim = 1\n","\n","model = DCRNN(NUM_NODES, input_dim, hidden_dim, output_dim, adj_mx, dropout=0.2, num_layers=3).to(device)\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","criterion = nn.MSELoss()\n","\n","EPOCHS = 50\n","best_val_loss = float('inf')    # Track best loss\n","\n","best_model_path = f\"{data_dir}/dcrnn_325nodes_best.pth\"\n","\n","for epoch in range(EPOCHS):\n","    # ------------------------\n","    # TRAINING\n","    # ------------------------\n","    model.train()\n","    train_loss = 0\n","\n","    for Xb, Yb in train_loader:\n","        Xb, Yb = Xb.to(device), Yb.to(device)\n","        optimizer.zero_grad()\n","\n","        preds = model(Xb)               # (B, 1, N, 1)\n","        target = Yb[:, -1:, :, 0:1]     # final step target\n","\n","        loss = criterion(preds, target)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item()\n","\n","    # ------------------------\n","    # VALIDATION\n","    # ------------------------\n","    model.eval()\n","    val_loss = 0\n","    with torch.no_grad():\n","        for Xb, Yb in val_loader:\n","            preds = model(Xb.to(device))\n","            target = Yb[:, -1:, :, 0:1].to(device)\n","            val_loss += criterion(preds, target).item()\n","\n","    avg_train = train_loss / len(train_loader)\n","    avg_val   = val_loss   / len(val_loader)\n","\n","    print(f\"Epoch {epoch+1}/{EPOCHS}  Train={avg_train:.6f}  Val={avg_val:.6f}\")\n","\n","    # ------------------------\n","    # SAVE BEST MODEL\n","    # ------------------------\n","    if avg_val < best_val_loss:\n","        best_val_loss = avg_val\n","        torch.save(model.state_dict(), best_model_path)\n","        print(f\"ðŸ”¥ Saved BEST model (Val loss = {best_val_loss:.6f}) at: {best_model_path}\")\n","\n","# ============================================================\n","# FINAL PRINT\n","# ============================================================\n","print(f\"\\nTraining done. Best model saved at:\\n â†’ {best_model_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":947},"id":"0wXN5TnLATow","executionInfo":{"status":"error","timestamp":1764027936936,"user_tz":300,"elapsed":1082856,"user":{"displayName":"Krishna Sharma","userId":"06839551360419294155"}},"outputId":"d394459f-9d26-416b-a801-c27eb6f7b7ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Using device: cuda\n","Loaded shapes: (36481, 325, 3) (5211, 325, 3) (10424, 325, 3)\n","Train shape: (36481, 325, 3)\n","Val shape: (5211, 325, 3)\n","Test shape: (10424, 325, 3)\n","Adjacency shape: (325, 325)\n","Sequence shapes:\n","X_train: (36466, 12, 325, 3)\n","Y_train: (36466, 3, 325, 3)\n","Epoch 1/50  Train=0.366226  Val=0.365691\n","ðŸ”¥ Saved BEST model (Val loss = 0.365691) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 2/50  Train=0.301338  Val=0.346346\n","ðŸ”¥ Saved BEST model (Val loss = 0.346346) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 3/50  Train=0.280765  Val=0.318477\n","ðŸ”¥ Saved BEST model (Val loss = 0.318477) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 4/50  Train=0.268759  Val=0.306476\n","ðŸ”¥ Saved BEST model (Val loss = 0.306476) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 5/50  Train=0.261367  Val=0.298220\n","ðŸ”¥ Saved BEST model (Val loss = 0.298220) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 6/50  Train=0.256496  Val=0.295862\n","ðŸ”¥ Saved BEST model (Val loss = 0.295862) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 7/50  Train=0.252581  Val=0.289957\n","ðŸ”¥ Saved BEST model (Val loss = 0.289957) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 8/50  Train=0.250047  Val=0.287040\n","ðŸ”¥ Saved BEST model (Val loss = 0.287040) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 9/50  Train=0.247238  Val=0.287313\n","Epoch 10/50  Train=0.245697  Val=0.290070\n","Epoch 11/50  Train=0.243856  Val=0.288607\n","Epoch 12/50  Train=0.241937  Val=0.280332\n","ðŸ”¥ Saved BEST model (Val loss = 0.280332) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2887735597.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[0;34m)\u001b[0m               \u001b[0;31m# (B, 1, N, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m     \u001b[0;31m# final step target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-2887735597.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0minput_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;31m# (B, N, F)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                 \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m                 \u001b[0minput_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;31m# output of one layer becomes input to next\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-2887735597.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h_prev, adj)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_prev\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mdiff_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0mdiff_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         h_new = self.gru(diff_out.reshape(-1, self.hidden_dim),\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-2887735597.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, adj)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# x: (B, N, F)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ij,bjf->bif\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# diffusion step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bif,fo->bio\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m                          \u001b[0;31m# dropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;31m# the path for contracting 0 or 1 time(s) is already optimized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;31m# or the user has disabled using opt_einsum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["Multilayer DCRNN (3 layers, 128 units each, dropout=0.2)\n"],"metadata":{"id":"2FCPXvN6TjYx"}},{"cell_type":"code","source":["# ============================================================\n","# STEP 1 â€” Google Drive + Imports\n","# ============================================================\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","import pickle\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","# ============================================================\n","# STEP 2 â€” Load Normalized Data\n","# ============================================================\n","data_dir = \"/content/drive/MyDrive/traffic_data\"\n","\n","train_full = np.load(f\"{data_dir}/train_norm_PEMS_BAY.npz\")[\"data\"]\n","val_full   = np.load(f\"{data_dir}/val_norm_PEMS_BAY.npz\")[\"data\"]\n","test_full  = np.load(f\"{data_dir}/test_norm_PEMS_BAY.npz\")[\"data\"]\n","\n","print(\"Loaded shapes:\", train_full.shape, val_full.shape, test_full.shape)\n","\n","# Limit timesteps EXACTLY as requested\n","train_data = train_full[:36481]   # (1000, 325, 3)\n","val_data   = val_full[:5211]      # (100, 325, 3)\n","test_data  = test_full[:10424]     # (200, 325, 3)\n","\n","print(\"Train shape:\", train_data.shape)\n","print(\"Val shape:\",   val_data.shape)\n","print(\"Test shape:\",  test_data.shape)\n","\n","# ============================================================\n","# STEP 3 â€” Load REAL 325Ã—325 Adjacency Matrix\n","# ============================================================\n","adj_path = f\"{data_dir}/adj_mx_bay.pkl/adj_mx_bay.pkl\"\n","\n","with open(adj_path, \"rb\") as f:\n","    sensor_ids, sensor_id_to_ind, adj_mx = pickle.load(f, encoding=\"latin1\")\n","\n","adj_mx = np.array(adj_mx).astype(np.float32)\n","NUM_NODES = adj_mx.shape[0]\n","\n","print(\"Adjacency shape:\", adj_mx.shape)   # (325, 325)\n","\n","\n","# ============================================================\n","# STEP 4 â€” Build Temporal Sequences\n","# ============================================================\n","def create_sequences(data, seq_len=12, pred_len=3):\n","    \"\"\"\n","    data: (T, N, F)\n","    returns:\n","       X: (B, seq_len, N, F)\n","       Y: (B, pred_len, N, F)\n","    \"\"\"\n","    T = data.shape[0]\n","    X, Y = [], []\n","\n","    for i in range(T - seq_len - pred_len):\n","        X.append(data[i:i+seq_len])\n","        Y.append(data[i+seq_len:i+seq_len+pred_len])\n","\n","    X = np.array(X)\n","    Y = np.array(Y)\n","    return X, Y\n","\n","# Build sequences\n","seq_len = 12\n","pred_len = 3\n","\n","X_train, Y_train = create_sequences(train_data, seq_len, pred_len)\n","X_val, Y_val     = create_sequences(val_data, seq_len, pred_len)\n","X_test, Y_test   = create_sequences(test_data, seq_len, pred_len)\n","\n","print(\"Sequence shapes:\")\n","print(\"X_train:\", X_train.shape)\n","print(\"Y_train:\", Y_train.shape)\n","\n","\n","# ============================================================\n","# STEP 5 â€” DataLoaders\n","# ============================================================\n","def to_loader(X, Y, batch=32, shuffle=True):\n","    return DataLoader(\n","        TensorDataset(torch.FloatTensor(X), torch.FloatTensor(Y)),\n","        batch_size=batch,\n","        shuffle=shuffle\n","    )\n","\n","train_loader = to_loader(X_train, Y_train)\n","val_loader   = to_loader(X_val, Y_val)\n","test_loader  = to_loader(X_test, Y_test)\n","\n","\n","# ============================================================\n","# STEP 6 â€” DCRNN MODEL\n","# ============================================================\n","# ============================================================\n","# STEP 6 â€” DCRNN MODEL (with dropout=0.2)\n","# ============================================================\n","# ============================================================\n","# STEP 6 â€” Multilayer DCRNN (5 layers, 128 units each, dropout=0.2)\n","# ============================================================\n","class DiffusionConv(nn.Module):\n","    def __init__(self, num_nodes, input_dim, output_dim, dropout=0.2):\n","        super().__init__()\n","        self.theta = nn.Parameter(torch.randn(input_dim, output_dim))\n","        nn.init.xavier_uniform_(self.theta)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, adj):\n","        # x: (B, N, F)\n","        out = torch.einsum(\"ij,bjf->bif\", adj, x)        # diffusion step\n","        out = torch.einsum(\"bif,fo->bio\", out, self.theta)\n","        out = self.dropout(out)                          # dropout\n","        return out\n","\n","\n","class DCRNNCell(nn.Module):\n","    def __init__(self, num_nodes, input_dim, hidden_dim, dropout=0.2):\n","        super().__init__()\n","        self.num_nodes = num_nodes\n","        self.hidden_dim = hidden_dim\n","\n","        self.diff = DiffusionConv(num_nodes, input_dim + hidden_dim, hidden_dim, dropout)\n","        self.gru = nn.GRUCell(hidden_dim, hidden_dim)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, h_prev, adj):\n","        combined = torch.cat([x, h_prev], dim=-1)\n","        diff_out = self.diff(combined, adj)\n","        diff_out = self.dropout(diff_out)\n","        h_new = self.gru(diff_out.reshape(-1, self.hidden_dim),\n","                         h_prev.reshape(-1, self.hidden_dim))\n","        return h_new.reshape(-1, self.num_nodes, self.hidden_dim)\n","\n","\n","class DCRNN(nn.Module):\n","    def __init__(self, num_nodes, input_dim, hidden_dim, output_dim, adj, dropout=0.2, num_layers=5):\n","        super().__init__()\n","        self.num_nodes = num_nodes\n","        self.hidden_dim = hidden_dim\n","        self.num_layers = num_layers\n","\n","        # -------- Create 5 stacked DCRNN layers --------\n","        layers = []\n","        for i in range(num_layers):\n","            in_dim = input_dim if i == 0 else hidden_dim\n","            layers.append(DCRNNCell(num_nodes, in_dim, hidden_dim, dropout))\n","\n","        self.layers = nn.ModuleList(layers)\n","\n","        # Final output projection\n","        self.fc_dropout = nn.Dropout(dropout)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","        self.register_buffer(\"adj\", torch.FloatTensor(adj))\n","\n","    def forward(self, x):\n","        B, T, N, F = x.shape\n","        h = [torch.zeros(B, N, self.hidden_dim, device=x.device)\n","             for _ in range(self.num_layers)]\n","\n","        for t in range(T):\n","            input_t = x[:, t]   # (B, N, F)\n","            for l in range(self.num_layers):\n","                h[l] = self.layers[l](input_t, h[l], self.adj)\n","                input_t = h[l]   # output of one layer becomes input to next\n","\n","        out = self.fc_dropout(h[-1])\n","        out = self.fc(out)\n","        return out.unsqueeze(1)\n","\n","\n","\n","\n","# ============================================================\n","# STEP 7 â€” TRAIN DCRNN\n","# ============================================================\n","# ============================================================\n","# STEP 7 â€” TRAIN DCRNN (Save best validation model)\n","# ============================================================\n","input_dim = 3\n","hidden_dim = 128\n","output_dim = 1\n","\n","model = DCRNN(NUM_NODES, input_dim, hidden_dim, output_dim, adj_mx, dropout=0.2, num_layers=3).to(device)\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","criterion = nn.MSELoss()\n","\n","EPOCHS = 50\n","best_val_loss = float('inf')    # Track best loss\n","\n","best_model_path = f\"{data_dir}/dcrnn_325nodes_best.pth\"\n","\n","for epoch in range(EPOCHS):\n","    # ------------------------\n","    # TRAINING\n","    # ------------------------\n","    model.train()\n","    train_loss = 0\n","\n","    for Xb, Yb in train_loader:\n","        Xb, Yb = Xb.to(device), Yb.to(device)\n","        optimizer.zero_grad()\n","\n","        preds = model(Xb)               # (B, 1, N, 1)\n","        target = Yb[:, -1:, :, 0:1]     # final step target\n","\n","        loss = criterion(preds, target)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item()\n","\n","    # ------------------------\n","    # VALIDATION\n","    # ------------------------\n","    model.eval()\n","    val_loss = 0\n","    with torch.no_grad():\n","        for Xb, Yb in val_loader:\n","            preds = model(Xb.to(device))\n","            target = Yb[:, -1:, :, 0:1].to(device)\n","            val_loss += criterion(preds, target).item()\n","\n","    avg_train = train_loss / len(train_loader)\n","    avg_val   = val_loss   / len(val_loader)\n","\n","    print(f\"Epoch {epoch+1}/{EPOCHS}  Train={avg_train:.6f}  Val={avg_val:.6f}\")\n","\n","    # ------------------------\n","    # SAVE BEST MODEL\n","    # ------------------------\n","    if avg_val < best_val_loss:\n","        best_val_loss = avg_val\n","        torch.save(model.state_dict(), best_model_path)\n","        print(f\"ðŸ”¥ Saved BEST model (Val loss = {best_val_loss:.6f}) at: {best_model_path}\")\n","\n","# ============================================================\n","# FINAL PRINT\n","# ============================================================\n","print(f\"\\nTraining done. Best model saved at:\\n â†’ {best_model_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":923},"id":"9t3NUzizTC7g","executionInfo":{"status":"error","timestamp":1764099205047,"user_tz":300,"elapsed":3225196,"user":{"displayName":"Krishna Sharma","userId":"06839551360419294155"}},"outputId":"27675865-f4e3-41a3-d492-573924bcd02d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Using device: cuda\n","Loaded shapes: (36481, 325, 3) (5211, 325, 3) (10424, 325, 3)\n","Train shape: (36481, 325, 3)\n","Val shape: (5211, 325, 3)\n","Test shape: (10424, 325, 3)\n","Adjacency shape: (325, 325)\n","Sequence shapes:\n","X_train: (36466, 12, 325, 3)\n","Y_train: (36466, 3, 325, 3)\n","Epoch 1/50  Train=0.362205  Val=0.357451\n","ðŸ”¥ Saved BEST model (Val loss = 0.357451) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 2/50  Train=0.291393  Val=0.326213\n","ðŸ”¥ Saved BEST model (Val loss = 0.326213) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 3/50  Train=0.271285  Val=0.313607\n","ðŸ”¥ Saved BEST model (Val loss = 0.313607) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 4/50  Train=0.260252  Val=0.307929\n","ðŸ”¥ Saved BEST model (Val loss = 0.307929) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 5/50  Train=0.252543  Val=0.305494\n","ðŸ”¥ Saved BEST model (Val loss = 0.305494) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 6/50  Train=0.248148  Val=0.290322\n","ðŸ”¥ Saved BEST model (Val loss = 0.290322) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 7/50  Train=0.243933  Val=0.282601\n","ðŸ”¥ Saved BEST model (Val loss = 0.282601) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 8/50  Train=0.241424  Val=0.282686\n","Epoch 9/50  Train=0.239436  Val=0.276766\n","ðŸ”¥ Saved BEST model (Val loss = 0.276766) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 10/50  Train=0.237485  Val=0.276400\n","ðŸ”¥ Saved BEST model (Val loss = 0.276400) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 11/50  Train=0.236189  Val=0.275502\n","ðŸ”¥ Saved BEST model (Val loss = 0.275502) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 12/50  Train=0.233465  Val=0.276309\n","Epoch 13/50  Train=0.232885  Val=0.273496\n","ðŸ”¥ Saved BEST model (Val loss = 0.273496) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 14/50  Train=0.230736  Val=0.270154\n","ðŸ”¥ Saved BEST model (Val loss = 0.270154) at: /content/drive/MyDrive/traffic_data/dcrnn_325nodes_best.pth\n","Epoch 15/50  Train=0.231381  Val=0.283998\n","Epoch 16/50  Train=0.229717  Val=0.270630\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1655090647.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;31m# ------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}