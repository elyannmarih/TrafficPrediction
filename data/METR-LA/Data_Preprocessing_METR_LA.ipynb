{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPxrls689NacjqM88/FPT3X"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Mount Google Drive"],"metadata":{"id":"8krVh6Vsrwul"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"Le_Pci3rD-RE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758834012810,"user_tz":240,"elapsed":18424,"user":{"displayName":"Elyann Soto Martinez","userId":"14958581501004434969"}},"outputId":"57e14d03-b319-4c76-d3dc-6259d4d42007"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["#Verify that the file is in Drive"],"metadata":{"id":"HkOGLR1WruXg"}},{"cell_type":"code","source":["import os\n","print(os.listdir(\"/content/drive/MyDrive/traffic_data\"))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZO55owEcrlNF","executionInfo":{"status":"ok","timestamp":1758834102081,"user_tz":240,"elapsed":223,"user":{"displayName":"Elyann Soto Martinez","userId":"14958581501004434969"}},"outputId":"ed37e1c0-ceb6-4f77-bd7d-40d54bda08b1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["['METR-LA.h5']\n"]}]},{"cell_type":"markdown","source":["#Open and clean the dataset"],"metadata":{"id":"QqMeDfdKr1TP"}},{"cell_type":"markdown","source":["##Open dataset"],"metadata":{"id":"zWDrhD1Mzp6i"}},{"cell_type":"code","source":["import pandas as pd\n","\n","file_path = \"/content/drive/MyDrive/traffic_data/METR-LA.h5\"\n","df = pd.read_hdf(file_path, 'df')\n","print(df.shape)\n","print(df.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3nTz-eE-rrGe","executionInfo":{"status":"ok","timestamp":1758834548161,"user_tz":240,"elapsed":1747,"user":{"displayName":"Elyann Soto Martinez","userId":"14958581501004434969"}},"outputId":"17ff40f9-878c-4d01-d2c9-e60344289bd0"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["(34272, 207)\n","                        773869     767541     767542     717447     717446  \\\n","2012-03-01 00:00:00  64.375000  67.625000  67.125000  61.500000  66.875000   \n","2012-03-01 00:05:00  62.666667  68.555556  65.444444  62.444444  64.444444   \n","2012-03-01 00:10:00  64.000000  63.750000  60.000000  59.000000  66.500000   \n","2012-03-01 00:15:00   0.000000   0.000000   0.000000   0.000000   0.000000   \n","2012-03-01 00:20:00   0.000000   0.000000   0.000000   0.000000   0.000000   \n","\n","                        717445  773062  767620     737529     717816  ...  \\\n","2012-03-01 00:00:00  68.750000  65.125  67.125  59.625000  62.750000  ...   \n","2012-03-01 00:05:00  68.111111  65.000  65.000  57.444444  63.333333  ...   \n","2012-03-01 00:10:00  66.250000  64.500  64.250  63.875000  65.375000  ...   \n","2012-03-01 00:15:00   0.000000   0.000   0.000   0.000000   0.000000  ...   \n","2012-03-01 00:20:00   0.000000   0.000   0.000   0.000000   0.000000  ...   \n","\n","                        772167  769372     774204     769806  717590  \\\n","2012-03-01 00:00:00  45.625000  65.500  64.500000  66.428571  66.875   \n","2012-03-01 00:05:00  50.666667  69.875  66.666667  58.555556  62.000   \n","2012-03-01 00:10:00  44.125000  69.000  56.500000  59.250000  68.125   \n","2012-03-01 00:15:00   0.000000   0.000   0.000000   0.000000   0.000   \n","2012-03-01 00:20:00   0.000000   0.000   0.000000   0.000000   0.000   \n","\n","                        717592     717595     772168     718141  769373  \n","2012-03-01 00:00:00  59.375000  69.000000  59.250000  69.000000  61.875  \n","2012-03-01 00:05:00  61.111111  64.444444  55.888889  68.444444  62.875  \n","2012-03-01 00:10:00  62.500000  65.625000  61.375000  69.857143  62.000  \n","2012-03-01 00:15:00   0.000000   0.000000   0.000000   0.000000   0.000  \n","2012-03-01 00:20:00   0.000000   0.000000   0.000000   0.000000   0.000  \n","\n","[5 rows x 207 columns]\n"]}]},{"cell_type":"markdown","source":["##Convert Kaggle METR-LA to DCRNN format"],"metadata":{"id":"AUVLJPmNwgki"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import h5py\n","\n","# 1. Load the Kaggle DataFrame\n","file_path = \"/content/drive/MyDrive/traffic_data/METR-LA.h5\"\n","df = pd.read_hdf(file_path, 'df')   # shape (34272, 207)\n","print(\"Original shape:\", df.shape)\n","\n","# 2. Extract speed matrix\n","speed = df.values.astype(np.float32)   # [time, sensors]\n","timestamps = df.index                  # DateTimeIndex\n","num_timesteps, num_sensors = speed.shape\n","\n","# 3. Build extra features (time-of-day, day-of-week)\n","time_of_day = (timestamps.hour * 60 + timestamps.minute) / (24 * 60)\n","day_of_week = timestamps.dayofweek / 7\n","\n","# Repeat across all sensors so shapes match\n","tod_expanded = np.tile(time_of_day.values[:, None], (1, num_sensors))\n","dow_expanded = np.tile(day_of_week.values[:, None], (1, num_sensors))\n","\n","# 4. Stack into final array [time, sensors, 3]\n","data = np.stack([speed, tod_expanded, dow_expanded], axis=-1)\n","print(\"New data shape:\", data.shape)  # expected (34272, 207, 3)\n","\n","# 5. Save to h5 file in DCRNN format\n","out_path = \"/content/drive/MyDrive/traffic_data/metr-la-dcrnn.h5\"\n","with h5py.File(out_path, 'w') as f:\n","    f.create_dataset(\"speed\", data=data)                   # [T, N, 3]\n","    f.create_dataset(\"time\", data=timestamps.astype(str).values)  # convert to string format\n","    f.create_dataset(\"dayofweek\", data=timestamps.dayofweek.values)\n","\n","print(f\"Saved converted dataset to {out_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JacHNjhPwhLP","executionInfo":{"status":"ok","timestamp":1758835428356,"user_tz":240,"elapsed":799,"user":{"displayName":"Elyann Soto Martinez","userId":"14958581501004434969"}},"outputId":"e412aa77-a056-4b92-cdb2-a166838dc486"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Original shape: (34272, 207)\n","New data shape: (34272, 207, 3)\n","Saved converted dataset to /content/drive/MyDrive/traffic_data/metr-la-dcrnn.h5\n"]}]},{"cell_type":"markdown","source":["##Verify the Converted Dataset"],"metadata":{"id":"fpMBwcIIwwrF"}},{"cell_type":"code","source":["import h5py\n","\n","# Path to the new file\n","out_path = \"/content/drive/MyDrive/traffic_data/metr-la-dcrnn.h5\"\n","\n","with h5py.File(out_path, 'r') as f:\n","    print(\"Keys in file:\", list(f.keys()))\n","\n","    speed = f['speed'][:]\n","    time = f['time'][:]\n","    dow = f['dayofweek'][:]\n","\n","    print(\"Speed shape:\", speed.shape)   # should be (34272, 207, 3)\n","    print(\"Time shape:\", time.shape)     # should be (34272,)\n","    print(\"Day-of-week shape:\", dow.shape)  # should be (34272,)\n","\n","    # Peek at first row\n","    print(\"First speed row (sensor 0):\", speed[0, 0, :])\n","    print(\"First timestamp:\", time[0])\n","    print(\"First day-of-week:\", dow[0])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yCfCn7K_wxK9","executionInfo":{"status":"ok","timestamp":1758835453990,"user_tz":240,"elapsed":933,"user":{"displayName":"Elyann Soto Martinez","userId":"14958581501004434969"}},"outputId":"cbb6c847-dfe0-4c29-c975-a65aec61a6d8"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Keys in file: ['dayofweek', 'speed', 'time']\n","Speed shape: (34272, 207, 3)\n","Time shape: (34272,)\n","Day-of-week shape: (34272,)\n","First speed row (sensor 0): [64.375       0.          0.42857143]\n","First timestamp: b'2012-03-01 00:00:00'\n","First day-of-week: 3\n"]}]},{"cell_type":"markdown","source":["##Replace zeros with NaN"],"metadata":{"id":"CJkAGwuYx4FG"}},{"cell_type":"code","source":["#Zeros in METR-LA usually mean “no reading.” We’ll turn them into NaN so we can handle them properly.\n","import numpy as np\n","\n","# data: (34272, 207, 3)\n","# feature 0 = speed\n","speeds = data[:, :, 0]   # extract just speed\n","\n","# replace 0.0 with NaN\n","speeds = np.where(speeds == 0.0, np.nan, speeds)\n","print(\"After replacing 0.0:\", np.isnan(speeds).sum(), \"missing values\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0_cQ6QT7x2HC","executionInfo":{"status":"ok","timestamp":1758835971540,"user_tz":240,"elapsed":64,"user":{"displayName":"Elyann Soto Martinez","userId":"14958581501004434969"}},"outputId":"c9ecb293-ae69-4283-b310-60fb990e3234"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["After replacing 0.0: 575302 missing values\n"]}]},{"cell_type":"markdown","source":["##Forward-fill per sensor"],"metadata":{"id":"NiYSTkpByi80"}},{"cell_type":"code","source":["#We want to fill NaNs using the last valid value for each sensor, along the time axis.\n","import pandas as pd\n","\n","# convert to DataFrame to use pandas forward fill\n","df_speeds = pd.DataFrame(speeds)\n","\n","# forward fill along time\n","df_speeds = df_speeds.fillna(method='ffill')\n","\n","# if still NaN at the very beginning, keep them for next step\n","print(\"Remaining NaNs after forward fill:\", df_speeds.isna().sum().sum())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wrOGk8vryjvM","executionInfo":{"status":"ok","timestamp":1758835976100,"user_tz":240,"elapsed":129,"user":{"displayName":"Elyann Soto Martinez","userId":"14958581501004434969"}},"outputId":"cf1f0de8-2f5a-40b8-c6c8-a0a699fe5e51"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Remaining NaNs after forward fill: 66\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3889462500.py:8: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n","  df_speeds = df_speeds.fillna(method='ffill')\n"]}]},{"cell_type":"markdown","source":["##Fill leading NaNs (start of dataset)"],"metadata":{"id":"9i-7a0ncypFv"}},{"cell_type":"code","source":["# compute column medians (ignoring NaN)\n","col_medians = df_speeds.median()\n","\n","# fill remaining NaNs with column medians\n","df_speeds = df_speeds.fillna(col_medians)\n","\n","# convert back to numpy\n","speeds_clean = df_speeds.values.astype(np.float32)\n","print(\"Remaining NaNs after fixing:\", np.isnan(speeds_clean).sum())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VunUkDT8yqAT","executionInfo":{"status":"ok","timestamp":1758835980316,"user_tz":240,"elapsed":392,"user":{"displayName":"Elyann Soto Martinez","userId":"14958581501004434969"}},"outputId":"61041304-695f-4fd6-acfe-a1f41457691c"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Remaining NaNs after fixing: 0\n"]}]},{"cell_type":"markdown","source":["##Rebuild the 3-feature array"],"metadata":{"id":"8Bze1FQwyrtx"}},{"cell_type":"code","source":["#Now put the cleaned speeds back together with time-of-day and day-of-week.\n","data_clean = np.stack([speeds_clean, data[:, :, 1], data[:, :, 2]], axis=-1)\n","print(\"Final cleaned data shape:\", data_clean.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ih1TyYjrytZ7","executionInfo":{"status":"ok","timestamp":1758835982531,"user_tz":240,"elapsed":68,"user":{"displayName":"Elyann Soto Martinez","userId":"14958581501004434969"}},"outputId":"dba0e2ea-0c18-4cb3-c9cb-16501258c2c0"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Final cleaned data shape: (34272, 207, 3)\n"]}]},{"cell_type":"markdown","source":["# z-score normalization"],"metadata":{"id":"onedM5NPy4Gl"}},{"cell_type":"markdown","source":["##Split chronologically"],"metadata":{"id":"jfp9LI_Szt_t"}},{"cell_type":"code","source":["T = data_clean.shape[0]   # total timesteps\n","train_end = int(T * 0.7)\n","val_end   = int(T * 0.8)\n","\n","train_data = data_clean[:train_end]\n","val_data   = data_clean[train_end:val_end]\n","test_data  = data_clean[val_end:]\n","\n","print(\"Train:\", train_data.shape, \"Val:\", val_data.shape, \"Test:\", test_data.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fZ3L9hyrzvzm","executionInfo":{"status":"ok","timestamp":1758836235160,"user_tz":240,"elapsed":11,"user":{"displayName":"Elyann Soto Martinez","userId":"14958581501004434969"}},"outputId":"5ab66c51-d33a-4f84-8fbc-c2a493fd7acf"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Train: (23990, 207, 3) Val: (3427, 207, 3) Test: (6855, 207, 3)\n"]}]},{"cell_type":"markdown","source":["##Compute mean and std from training only"],"metadata":{"id":"Y5mvk9LJz1Fp"}},{"cell_type":"code","source":["# compute mean and std per sensor using training set. We normalize the speed feature (index 0) per sensor.\n","train_speeds = train_data[:, :, 0]   # shape (23990, 207)\n","\n","mean_per_sensor = train_speeds.mean(axis=0, keepdims=True)   # shape (1, 207)\n","std_per_sensor  = train_speeds.std(axis=0, keepdims=True)    # shape (1, 207)\n","\n","print(\"Mean shape:\", mean_per_sensor.shape, \"Std shape:\", std_per_sensor.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9SP_q59iz114","executionInfo":{"status":"ok","timestamp":1758836275587,"user_tz":240,"elapsed":61,"user":{"displayName":"Elyann Soto Martinez","userId":"14958581501004434969"}},"outputId":"e57c06fe-5dec-42ad-d288-40492c440b53"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean shape: (1, 207) Std shape: (1, 207)\n"]}]},{"cell_type":"markdown","source":["##Apply z-score normalization"],"metadata":{"id":"BJHD5KLrz8BN"}},{"cell_type":"code","source":["#Apply (x - mean) / std to train, val, test.\n","def normalize(dataset, mean, std):\n","    speeds = dataset[:, :, 0]\n","    norm_speeds = (speeds - mean) / (std + 1e-6)  # avoid division by zero\n","    # rebuild with normalized speeds + original time/day features\n","    return np.stack([norm_speeds, dataset[:, :, 1], dataset[:, :, 2]], axis=-1)\n","\n","train_norm = normalize(train_data, mean_per_sensor, std_per_sensor)\n","val_norm   = normalize(val_data, mean_per_sensor, std_per_sensor)\n","test_norm  = normalize(test_data, mean_per_sensor, std_per_sensor)\n","\n","print(\"Normalized train shape:\", train_norm.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n2RdoZIp0A78","executionInfo":{"status":"ok","timestamp":1758836357603,"user_tz":240,"elapsed":117,"user":{"displayName":"Elyann Soto Martinez","userId":"14958581501004434969"}},"outputId":"8efa8596-42c4-4467-deba-c868bca9cd25"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Normalized train shape: (23990, 207, 3)\n"]}]},{"cell_type":"markdown","source":["##Save mean/std for later (denormalization)"],"metadata":{"id":"RN7a7F290GTN"}},{"cell_type":"code","source":["# Save normalization stats (for later denormalization)\n","np.savez(\"/content/drive/MyDrive/traffic_data/normalization_stats.npz\",\n","         mean=mean_per_sensor, std=std_per_sensor)\n","\n","# Save normalized train/val/test splits\n","np.savez(\"/content/drive/MyDrive/traffic_data/train_norm.npz\", data=train_norm)\n","np.savez(\"/content/drive/MyDrive/traffic_data/val_norm.npz\", data=val_norm)\n","np.savez(\"/content/drive/MyDrive/traffic_data/test_norm.npz\", data=test_norm)\n","\n","print(\"Saved normalization stats and train/val/test normalized splits.\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ufi-T-B40H7t","executionInfo":{"status":"ok","timestamp":1758836760411,"user_tz":240,"elapsed":1724,"user":{"displayName":"Elyann Soto Martinez","userId":"14958581501004434969"}},"outputId":"86aa5403-e495-451c-bbca-fb7fc58252ff"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved normalization stats and train/val/test normalized splits.\n"]}]}]}