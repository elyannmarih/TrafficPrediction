{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO8l6M+Lz6RWOYAfd9kWVYS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elyannmarih/TrafficPrediction/blob/main/Data_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mount Google Drive"
      ],
      "metadata": {
        "id": "8krVh6Vsrwul"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Le_Pci3rD-RE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57e14d03-b319-4c76-d3dc-6259d4d42007"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Verify that the file is in Drive"
      ],
      "metadata": {
        "id": "HkOGLR1WruXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir(\"/content/drive/MyDrive/traffic_data\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZO55owEcrlNF",
        "outputId": "ed37e1c0-ceb6-4f77-bd7d-40d54bda08b1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['METR-LA.h5']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Open and clean the dataset"
      ],
      "metadata": {
        "id": "QqMeDfdKr1TP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Open dataset"
      ],
      "metadata": {
        "id": "zWDrhD1Mzp6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/traffic_data/METR-LA.h5\"\n",
        "df = pd.read_hdf(file_path, 'df')\n",
        "print(df.shape)\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nTz-eE-rrGe",
        "outputId": "17ff40f9-878c-4d01-d2c9-e60344289bd0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(34272, 207)\n",
            "                        773869     767541     767542     717447     717446  \\\n",
            "2012-03-01 00:00:00  64.375000  67.625000  67.125000  61.500000  66.875000   \n",
            "2012-03-01 00:05:00  62.666667  68.555556  65.444444  62.444444  64.444444   \n",
            "2012-03-01 00:10:00  64.000000  63.750000  60.000000  59.000000  66.500000   \n",
            "2012-03-01 00:15:00   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
            "2012-03-01 00:20:00   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
            "\n",
            "                        717445  773062  767620     737529     717816  ...  \\\n",
            "2012-03-01 00:00:00  68.750000  65.125  67.125  59.625000  62.750000  ...   \n",
            "2012-03-01 00:05:00  68.111111  65.000  65.000  57.444444  63.333333  ...   \n",
            "2012-03-01 00:10:00  66.250000  64.500  64.250  63.875000  65.375000  ...   \n",
            "2012-03-01 00:15:00   0.000000   0.000   0.000   0.000000   0.000000  ...   \n",
            "2012-03-01 00:20:00   0.000000   0.000   0.000   0.000000   0.000000  ...   \n",
            "\n",
            "                        772167  769372     774204     769806  717590  \\\n",
            "2012-03-01 00:00:00  45.625000  65.500  64.500000  66.428571  66.875   \n",
            "2012-03-01 00:05:00  50.666667  69.875  66.666667  58.555556  62.000   \n",
            "2012-03-01 00:10:00  44.125000  69.000  56.500000  59.250000  68.125   \n",
            "2012-03-01 00:15:00   0.000000   0.000   0.000000   0.000000   0.000   \n",
            "2012-03-01 00:20:00   0.000000   0.000   0.000000   0.000000   0.000   \n",
            "\n",
            "                        717592     717595     772168     718141  769373  \n",
            "2012-03-01 00:00:00  59.375000  69.000000  59.250000  69.000000  61.875  \n",
            "2012-03-01 00:05:00  61.111111  64.444444  55.888889  68.444444  62.875  \n",
            "2012-03-01 00:10:00  62.500000  65.625000  61.375000  69.857143  62.000  \n",
            "2012-03-01 00:15:00   0.000000   0.000000   0.000000   0.000000   0.000  \n",
            "2012-03-01 00:20:00   0.000000   0.000000   0.000000   0.000000   0.000  \n",
            "\n",
            "[5 rows x 207 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Convert Kaggle METR-LA to DCRNN format"
      ],
      "metadata": {
        "id": "AUVLJPmNwgki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import h5py\n",
        "\n",
        "# 1. Load the Kaggle DataFrame\n",
        "file_path = \"/content/drive/MyDrive/traffic_data/METR-LA.h5\"\n",
        "df = pd.read_hdf(file_path, 'df')   # shape (34272, 207)\n",
        "print(\"Original shape:\", df.shape)\n",
        "\n",
        "# 2. Extract speed matrix\n",
        "speed = df.values.astype(np.float32)   # [time, sensors]\n",
        "timestamps = df.index                  # DateTimeIndex\n",
        "num_timesteps, num_sensors = speed.shape\n",
        "\n",
        "# 3. Build extra features (time-of-day, day-of-week)\n",
        "time_of_day = (timestamps.hour * 60 + timestamps.minute) / (24 * 60)\n",
        "day_of_week = timestamps.dayofweek / 7\n",
        "\n",
        "# Repeat across all sensors so shapes match\n",
        "tod_expanded = np.tile(time_of_day.values[:, None], (1, num_sensors))\n",
        "dow_expanded = np.tile(day_of_week.values[:, None], (1, num_sensors))\n",
        "\n",
        "# 4. Stack into final array [time, sensors, 3]\n",
        "data = np.stack([speed, tod_expanded, dow_expanded], axis=-1)\n",
        "print(\"New data shape:\", data.shape)  # expected (34272, 207, 3)\n",
        "\n",
        "# 5. Save to h5 file in DCRNN format\n",
        "out_path = \"/content/drive/MyDrive/traffic_data/metr-la-dcrnn.h5\"\n",
        "with h5py.File(out_path, 'w') as f:\n",
        "    f.create_dataset(\"speed\", data=data)                   # [T, N, 3]\n",
        "    f.create_dataset(\"time\", data=timestamps.astype(str).values)  # convert to string format\n",
        "    f.create_dataset(\"dayofweek\", data=timestamps.dayofweek.values)\n",
        "\n",
        "print(f\"Saved converted dataset to {out_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JacHNjhPwhLP",
        "outputId": "e412aa77-a056-4b92-cdb2-a166838dc486"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: (34272, 207)\n",
            "New data shape: (34272, 207, 3)\n",
            "Saved converted dataset to /content/drive/MyDrive/traffic_data/metr-la-dcrnn.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Verify the Converted Dataset"
      ],
      "metadata": {
        "id": "fpMBwcIIwwrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "\n",
        "# Path to the new file\n",
        "out_path = \"/content/drive/MyDrive/traffic_data/metr-la-dcrnn.h5\"\n",
        "\n",
        "with h5py.File(out_path, 'r') as f:\n",
        "    print(\"Keys in file:\", list(f.keys()))\n",
        "\n",
        "    speed = f['speed'][:]\n",
        "    time = f['time'][:]\n",
        "    dow = f['dayofweek'][:]\n",
        "\n",
        "    print(\"Speed shape:\", speed.shape)   # should be (34272, 207, 3)\n",
        "    print(\"Time shape:\", time.shape)     # should be (34272,)\n",
        "    print(\"Day-of-week shape:\", dow.shape)  # should be (34272,)\n",
        "\n",
        "    # Peek at first row\n",
        "    print(\"First speed row (sensor 0):\", speed[0, 0, :])\n",
        "    print(\"First timestamp:\", time[0])\n",
        "    print(\"First day-of-week:\", dow[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCfCn7K_wxK9",
        "outputId": "cbb6c847-dfe0-4c29-c975-a65aec61a6d8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys in file: ['dayofweek', 'speed', 'time']\n",
            "Speed shape: (34272, 207, 3)\n",
            "Time shape: (34272,)\n",
            "Day-of-week shape: (34272,)\n",
            "First speed row (sensor 0): [64.375       0.          0.42857143]\n",
            "First timestamp: b'2012-03-01 00:00:00'\n",
            "First day-of-week: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Replace zeros with NaN"
      ],
      "metadata": {
        "id": "CJkAGwuYx4FG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Zeros in METR-LA usually mean “no reading.” We’ll turn them into NaN so we can handle them properly.\n",
        "import numpy as np\n",
        "\n",
        "# data: (34272, 207, 3)\n",
        "# feature 0 = speed\n",
        "speeds = data[:, :, 0]   # extract just speed\n",
        "\n",
        "# replace 0.0 with NaN\n",
        "speeds = np.where(speeds == 0.0, np.nan, speeds)\n",
        "print(\"After replacing 0.0:\", np.isnan(speeds).sum(), \"missing values\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_cQ6QT7x2HC",
        "outputId": "c9ecb293-ae69-4283-b310-60fb990e3234"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After replacing 0.0: 575302 missing values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Forward-fill per sensor"
      ],
      "metadata": {
        "id": "NiYSTkpByi80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We want to fill NaNs using the last valid value for each sensor, along the time axis.\n",
        "import pandas as pd\n",
        "\n",
        "# convert to DataFrame to use pandas forward fill\n",
        "df_speeds = pd.DataFrame(speeds)\n",
        "\n",
        "# forward fill along time\n",
        "df_speeds = df_speeds.fillna(method='ffill')\n",
        "\n",
        "# if still NaN at the very beginning, keep them for next step\n",
        "print(\"Remaining NaNs after forward fill:\", df_speeds.isna().sum().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrOGk8vryjvM",
        "outputId": "cf1f0de8-2f5a-40b8-c6c8-a0a699fe5e51"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Remaining NaNs after forward fill: 66\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3889462500.py:8: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df_speeds = df_speeds.fillna(method='ffill')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fill leading NaNs (start of dataset)"
      ],
      "metadata": {
        "id": "9i-7a0ncypFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compute column medians (ignoring NaN)\n",
        "col_medians = df_speeds.median()\n",
        "\n",
        "# fill remaining NaNs with column medians\n",
        "df_speeds = df_speeds.fillna(col_medians)\n",
        "\n",
        "# convert back to numpy\n",
        "speeds_clean = df_speeds.values.astype(np.float32)\n",
        "print(\"Remaining NaNs after fixing:\", np.isnan(speeds_clean).sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VunUkDT8yqAT",
        "outputId": "61041304-695f-4fd6-acfe-a1f41457691c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Remaining NaNs after fixing: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Rebuild the 3-feature array"
      ],
      "metadata": {
        "id": "8Bze1FQwyrtx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Now put the cleaned speeds back together with time-of-day and day-of-week.\n",
        "data_clean = np.stack([speeds_clean, data[:, :, 1], data[:, :, 2]], axis=-1)\n",
        "print(\"Final cleaned data shape:\", data_clean.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ih1TyYjrytZ7",
        "outputId": "dba0e2ea-0c18-4cb3-c9cb-16501258c2c0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final cleaned data shape: (34272, 207, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# z-score normalization"
      ],
      "metadata": {
        "id": "onedM5NPy4Gl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Split chronologically"
      ],
      "metadata": {
        "id": "jfp9LI_Szt_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "T = data_clean.shape[0]   # total timesteps\n",
        "train_end = int(T * 0.7)\n",
        "val_end   = int(T * 0.8)\n",
        "\n",
        "train_data = data_clean[:train_end]\n",
        "val_data   = data_clean[train_end:val_end]\n",
        "test_data  = data_clean[val_end:]\n",
        "\n",
        "print(\"Train:\", train_data.shape, \"Val:\", val_data.shape, \"Test:\", test_data.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZ3L9hyrzvzm",
        "outputId": "5ab66c51-d33a-4f84-8fbc-c2a493fd7acf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (23990, 207, 3) Val: (3427, 207, 3) Test: (6855, 207, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Compute mean and std from training only"
      ],
      "metadata": {
        "id": "Y5mvk9LJz1Fp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compute mean and std per sensor using training set. We normalize the speed feature (index 0) per sensor.\n",
        "train_speeds = train_data[:, :, 0]   # shape (23990, 207)\n",
        "\n",
        "mean_per_sensor = train_speeds.mean(axis=0, keepdims=True)   # shape (1, 207)\n",
        "std_per_sensor  = train_speeds.std(axis=0, keepdims=True)    # shape (1, 207)\n",
        "\n",
        "print(\"Mean shape:\", mean_per_sensor.shape, \"Std shape:\", std_per_sensor.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SP_q59iz114",
        "outputId": "e57c06fe-5dec-42ad-d288-40492c440b53"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean shape: (1, 207) Std shape: (1, 207)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Apply z-score normalization"
      ],
      "metadata": {
        "id": "BJHD5KLrz8BN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply (x - mean) / std to train, val, test.\n",
        "def normalize(dataset, mean, std):\n",
        "    speeds = dataset[:, :, 0]\n",
        "    norm_speeds = (speeds - mean) / (std + 1e-6)  # avoid division by zero\n",
        "    # rebuild with normalized speeds + original time/day features\n",
        "    return np.stack([norm_speeds, dataset[:, :, 1], dataset[:, :, 2]], axis=-1)\n",
        "\n",
        "train_norm = normalize(train_data, mean_per_sensor, std_per_sensor)\n",
        "val_norm   = normalize(val_data, mean_per_sensor, std_per_sensor)\n",
        "test_norm  = normalize(test_data, mean_per_sensor, std_per_sensor)\n",
        "\n",
        "print(\"Normalized train shape:\", train_norm.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2RdoZIp0A78",
        "outputId": "8efa8596-42c4-4467-deba-c868bca9cd25"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized train shape: (23990, 207, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Save mean/std for later (denormalization)"
      ],
      "metadata": {
        "id": "RN7a7F290GTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save normalization stats (for later denormalization)\n",
        "np.savez(\"/content/drive/MyDrive/traffic_data/normalization_stats.npz\",\n",
        "         mean=mean_per_sensor, std=std_per_sensor)\n",
        "\n",
        "# Save normalized train/val/test splits\n",
        "np.savez(\"/content/drive/MyDrive/traffic_data/train_norm.npz\", data=train_norm)\n",
        "np.savez(\"/content/drive/MyDrive/traffic_data/val_norm.npz\", data=val_norm)\n",
        "np.savez(\"/content/drive/MyDrive/traffic_data/test_norm.npz\", data=test_norm)\n",
        "\n",
        "print(\"Saved normalization stats and train/val/test normalized splits.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufi-T-B40H7t",
        "outputId": "86aa5403-e495-451c-bbca-fb7fc58252ff"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved normalization stats and train/val/test normalized splits.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XA1hJw-b1oa4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}